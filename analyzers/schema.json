{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "text": {
      "type": "string",
      "description": "The input text"
    },
    "analyzer": {
      "type": "string",
      "$ref": "#/definitions/esanalyze"
    },
    "char_filter": {
      "type": "array",
      "description": "Convert original input text into a stream of characters then preprocess it before passing it as an input to tokenizer",
      "items": {
        "anyOf": [
          { "$ref": "#/definitions/escharfilter" },
          { "$ref": "#/definitions/escharfiltermap" },
          { "$ref": "#/definitions/escharfilterpattern" }
        ]
      }
    },
    "tokenizer": {
      "description": "Split the Output of Character Filters into Unique Terms",
      "anyOf": [
        { "$ref": "#/definitions/estokenizer" },
        { "$ref": "#/definitions/esngram" },
        { "$ref": "#/definitions/estokenizerstructpattern" },
        { "$ref": "#/definitions/estokenizerchargroup" },
        { "$ref": "#/definitions/estokenizerpathhierarchy" }
      ]
    },
    "filter": {
      "type": "array",
      "items": {
        "anyOf": [
          { "$ref": "#/definitions/estokenfilter" },
          { "$ref": "#/definitions/estokenfilter_asciifolding" },
          { "$ref": "#/definitions/esngram" },
          { "$ref": "#/definitions/estokenfilter_fingerprint" },
          { "$ref": "#/definitions/estokenfilter_keep" },
          { "$ref": "#/definitions/estokenfilter_keeptypes" },
          { "$ref": "#/definitions/estokenfilter_stemmer" },
          { "$ref": "#/definitions/estokenfilter_stop" },
          { "$ref": "#/definitions/estokenfilter_conditional" },
          { "$ref": "#/definitions/estokenfilter_predicate" },
          { "$ref": "#/definitions/estokenfilter_length" },
          { "$ref": "#/definitions/estokenfilter_worddelimiter" }
        ]
      }
    }
  },
  "definitions": {
    "esanalyze": {
      "type": "string",
      "default": "standard",
      "enum": [
        "standard",
        "simple",
        "whitespace",
        "stop",
        "keyword",
        "pattern",
        "arabic",
        "armenian",
        "basque",
        "bengali",
        "brazilian",
        "bulgarian",
        "catalan",
        "cjk",
        "czech",
        "danish",
        "dutch",
        "english",
        "estonian",
        "finnish",
        "french",
        "galician",
        "german",
        "greek",
        "hindi",
        "hungarian",
        "indonesian",
        "irish",
        "italian",
        "latvian",
        "lithuanian",
        "norwegian",
        "persian",
        "portuguese",
        "romanian",
        "russian",
        "sorani",
        "spanish",
        "swedish",
        "turkish",
        "thai",
        "kuromoji",
        "smartcn",
        "openkoreantext-analyzer"
      ]
    },

    "escharfilter": {
      "type": "string",

      "enum": ["html_strip", "pattern_replace"]
    },
    "escharfiltermap": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["mapping"]
        },
        "mappings": {
          "type": "array",
          "items": {
            "type": "string"
          }
        }
      }
    },
    "escharfilterpattern": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["pattern_replace"]
        },
        "pattern": {
          "description": "Regular expression for finding token",
          "type": "string"
        },
        "replacement": {
          "description": "Regular expression for replacing token",
          "type": "string"
        }
      }
    },
    "estokenizer": {
      "type": "string",
      "default": "standard",
      "enum": [
        "standard",
        "letter",
        "lowercase",
        "whitespace",
        "uax_url_email",
        "classic",
        "thai",
        "keyword",
        "pattern"
      ]
    },
    "esngram": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["ngram", "edge_ngram"]
        },
        "min_gram": {
          "description": "This slides along the input character stream to provide items in the specified length of the specified characters. It uses min_gram (this defaults to 1) and max_gram(this defaults to 2) to specify the length",
          "type": "integer",
          "default": 1
        },
        "max_gram": {
          "description": "This slides along the input character stream to provide items in the specified length of the specified characters. It uses min_gram (this defaults to 1) and max_gram(this defaults to 2) to specify the length",
          "type": "integer",
          "default": 2
        },
        "token_chars": {
          "description": "This slides along the input character stream to provide items in the specified length of the specified characters. token_chars is used to specify the letters, digits, whitespace, punctuation, and symbol.",
          "type": "array",
          "items": {
            "anyOf": [
              { "$ref": "#/definitions/estokentype" },
              { "type": "string" }
            ]
          }
        }
      }
    },
    "estokenizerstructpattern": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["pattern", "simple_pattern", "simple_pattern_split"]
        },
        "pattern": {
          "description": "Specify regular expression",
          "type": "string",
          "default": "\\W+"
        },
        "flag": {
          "description": "Specify the flag of the Java regular expression",
          "type": "string"
        },
        "group": {
          "description": "Specify the group matched",
          "type": "string"
        }
      }
    },
    "estokentype": {
      "type": "string",
      "enum": ["letter", "digit", "whitespace", "punctuation", "symbol"]
    },
    "estokenizerchargroup": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["char_group"]
        },
        "tokenize_on_chars": {
          "description": "You can define a set of separators to split the input character stream into terms. Use tokenize_on_chars to specify a list of separators.",
          "type": "array",
          "items": {
            "anyOf": [
              { "$ref": "#/definitions/estokentype" },
              { "type": "string" }
            ]
          }
        },
        "flag": {
          "description": "Specify the flag of the Java regular expression",
          "type": "string"
        },
        "group": {
          "description": "Specify the group matched",
          "type": "string"
        }
      }
    },
    "estokenizerpathhierarchy": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["path_hierarchy"]
        },
        "replacement": {
          "description": "This uses the path separator to split the input character stream into terms - replacement: the character to replace the delimiter",
          "type": "string"
        },
        "delimiter": {
          "description": "This uses the path separator to split the input character stream into terms - delimiter: the separator",
          "type": "string"
        },
        "buffer_size": {
          "description": "This uses the path separator to split the input character stream into terms - buffer_size: the maximum length in one batch",
          "type": "integer"
        },
        "reverse": {
          "description": "This uses the path separator to split the input character stream into terms - reverse: this reverses the generated terms",
          "type": "boolean"
        },
        "skip": {
          "description": "This uses the path separator to split the input character stream into terms - skip: the number of generated terms to skip",
          "type": "integer"
        }
      }
    },
    "estokenfilter": {
      "type": "string",
      "default": "lowercase",
      "enum": ["lowercase", "uppercase", "fingerprint", "unique", "reverse"]
    },
    "estokenfilter_asciifolding": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["asciifolding"]
        },
        "preserve_original": {
          "type": "boolean",
          "default": false,
          "description": "This transforms the terms when letters, numbers, and unicode symbols are not in the first 127 ASCII characters to ASCII - retain the original terms"
        }
      }
    },
    "estokenfilter_fingerprint": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["fingerprint"]
        },
        "separator": {
          "type": "string",
          "default": " ",
          "description": "Sort, deduplicate, and concatenate the terms from the tokenizer into one term. - The separator parameter (this defaults to the space character) can be set to another character. "
        },
        "max_output_size": {
          "type": "integer",
          "default": 255,
          "description": "Sort, deduplicate, and concatenate the terms from the tokenizer into one term. - The max_output_size parameter (this defaults to 255) will restrict the emitting of the final concatenated term. "
        }
      }
    },
    "estokenfilter_keep": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["keep"]
        },
        "keep_words": {
          "description": "Only those terms defined in the list of specified words are kept. Three options are provided: the keep_words parameter allows you to specify a list of words in the filter ",
          "type": "array",
          "items": {
            "type": "string"
          }
        },
        "keep_words_path": {
          "type": "array",
          "description": "the keep_words_path parameter allows you to specify a list of words in the file path; ",
          "items": {
            "type": "string"
          }
        },
        "keep_words_case": {
          "type": "boolean",
          "default": false,
          "description": "the keep_words_case parameter (this defaults to false) converts the terms to lowercase. "
        }
      }
    },
    "estokenfilter_keeptypes": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["keep_types"]
        },
        "types": {
          "description": "Only those terms defined in the list of specified token types are kept. ",
          "type": "array",
          "items": {
            "type": "string",
            "enum": ["<NUM>", "<ALPHANUM>", "<HANGUL>", "word", "<SYNONYM>"]
          }
        },
        "mode": {
          "type": "string",
          "description": "allows you to include or exclude the specified terms",
          "default": "include",
          "enum": ["include", "exclude"]
        }
      }
    },
    "estokenfilter_stemmer": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["stemmer"]
        },
        "name": {
          "description": "Allows to specify stemmer in different languages and apply it to the terms ",
          "$ref": "#/definitions/eslanguage"
        },
        "mode": {
          "type": "string",
          "description": "allows you to include or exclude the specified terms",
          "default": "include",
          "enum": ["include", "exclude"]
        }
      }
    },
    "estokenfilter_stop": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["stop"]
        },
        "stopwords": {
          "description": "Allows to specify stop words to delete from the terms",
          "type": "array",
          "items": { "$ref": "#/definitions/esstopwords" }
        },
        "stopwords_path": {
          "type": "string",
          "description": "specify a path relative to the config location that contains a list of words to remove"
        },
        "ignore_case": {
          "type": "boolean",
          "description": "lowercase all the terms first",
          "default": false
        },
        "remove_trailing": {
          "type": "boolean",
          "description": "ignore the last term",
          "default": false
        }
      }
    },
    "estokenfilter_conditional": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["condition"]
        },
        "script": {
          "description": "Allows to specify a predicate script",
          "$ref": "#/definitions/esscript"
        },
        "filter": {
          "type": "array",
          "description": "list of token filters applied to the terms if terms match",
          "items": { "$ref": "#/definitions/estokenfilter" }
        }
      }
    },
    "estokenfilter_predicate": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["predicate_token_filter"]
        },
        "script": {
          "description": "Allows to specify a predicate script",
          "$ref": "#/definitions/esscript"
        }
      }
    },
    "estokenfilter_length": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["length"]
        },
        "min": {
          "description": "Removes tokens longer than specified length",
          "type": "integer"
        },
        "max": {
          "description": "Removes tokens shorter than specified length",
          "type": "integer"
        }
      }
    },
    "estokenfilter_worddelimiter": {
      "type": "object",
      "properties": {
        "type": {
          "type": "string",
          "enum": ["word_delimiter"]
        },
        "generate_word_parts": {
          "type": "boolean",
          "description": "Generates subwords from a term when the case changes",
          "default": true
        },
        "generate_number_parts": {
          "type": "boolean",
          "description": "Generates a subnumber",
          "default": true
        },
        "catenate_words": {
          "type": "boolean",
          "description": "Concatenates the split word terms, which come from the same origin term, together",
          "default": false
        },
        "catenate_numbers": {
          "type": "boolean",
          "description": "Concatenates the split numeric terms, which come from the same origin term, together",
          "default": false
        },
        "catenate_all": {
          "type": "boolean",
          "description": "Concatenates the split numeric and word terms, which come from the same origin term, together",
          "default": false
        },
        "split_on_case_change": {
          "type": "boolean",
          "description": "The case changes are ignored when it is false",
          "default": true
        },
        "preserve_original": {
          "type": "boolean",
          "description": "The original terms from the tokenizer are preserved",
          "default": true
        },
        "split_on_numerics": {
          "type": "boolean",
          "description": "The numeric changes are ignored when false",
          "default": true
        },
        "stem_english_posessive": {
          "type": "boolean",
          "description": "Removes the apostrophe from the possessive adjective.",
          "default": true
        }
      }
    },
    "eslanguage": {
      "type": "string",
      "enum": [
        "arabic",
        "armenian",
        "basque",
        "bengali",
        "brazilian",
        "bulgarian",
        "catalan",
        "czech",
        "danish",
        "dutch",
        "dutch_kp",
        "english",
        "light_english",
        "lovins",
        "minimal_english",
        "porter2",
        "possessive_english",
        "estonian",
        "finnish",
        "light_finnish",
        "french",
        "light_french",
        "minimal_french",
        "galician",
        "minimal_galician",
        "german",
        "german2",
        "minimal_german",
        "light_german",
        "greek",
        "hindi",
        "hungarian",
        "light_hungarian",
        "indonesian",
        "irish",
        "italian",
        "light_italian",
        "latvian",
        "lithuanian",
        "norwegian",
        "light_norwegian",
        "minimal_norwegian",
        "light_nynorsk",
        "minimal_nynorsk",
        "portuguese",
        "light_portuguese",
        "minimal_portuguese",
        "portuguese_rslp",
        "romanian",
        "russian",
        "light_russian",
        "sorani",
        "spanish",
        "light_spanish",
        "swedish",
        "light_swedish",
        "turkish"
      ]
    },
    "esstopwords": {
      "type": "string",
      "default": "_english_",
      "enum": [
        "_arabic_",
        "_armenian_",
        "_basque_",
        "_bengali_",
        "_brazilian_",
        "_bulgarian_",
        "_catalan_",
        "_cjk_",
        "_czech_",
        "_danish_",
        "_dutch_",
        "_english_",
        "_estonian_",
        "_finnish_",
        "_french_",
        "_galician_",
        "_german_",
        "_greek_",
        "_hindi_",
        "_hungarian_",
        "_indonesian_",
        "_irish_",
        "_italian_",
        "_latvian_",
        "_lithuanian_",
        "_norwegian_",
        "_persian_",
        "_portuguese_",
        "_romanian_",
        "_russian_",
        "_sorani_",
        "_spanish_",
        "_swedish_",
        "_turkish_",
        "_thai_"
      ]
    },
    "esscript": {
      "type": "object",
      "properties": {
        "source": {
          "type": "string",
          "examples": ["token.getType()=='<ALPHANUM>'"]
        }
      }
    }
  }
}
